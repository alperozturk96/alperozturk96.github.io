<article class="post">
    <header class="post-header">
        <h1>Words That Often Get Overlooked</h1>
        <time datetime="2025-06-14">14 June 2025</time>
    </header>

    <main class="post-content">
        <section class="post-section">
            <p>
                Many engineers are familiar with terms like “concurrency”, “deadlock”, “thread” but sometimes the
                precise meanings can be a bit unclear.
            </p>

            <p>I hear a lot:</p>
            <ul>
                <li>“This should belong to the I/O thread.”</li>
                <li>“The app will crash otherwise.”</li>
                <li>“Why is there a mutex here?”</li>
                <li>“Shall we use semaphore?”</li>
                <li>“How did this code introduce a race condition?”</li>
                <li>“Can synchronized block solve this?”</li>
            </ul>
            <p>Before relying on memorized code or common answers, it’s valuable to truly understand what these concepts
                mean and why they matter.</p>
        </section>

        <section class="post-section">
            <h2>Being Skeptical</h2>
            <p>
                I have always been curious. I constantly ask “why” and “how.” I find that questioning and seeking
                clarity leads to deeper understanding.
                Being skeptical about technical matters has always helped me.
            </p>

            <p>
                When I come across new ideas or claims, I take the time to explore and verify them before accepting them
                as truth.
            </p>

            <p>
                I’ll try to summarize concurrency. If you spot any errors or have clearer explanations, feel free to
                contact me.
            </p>
        </section>

        <section class="post-section">
            <h2>Instruction Hierarchy</h2>

            <p>
                Computers only understand 0s and 1s. Over time, great engineers have helped us develop ways to write
                code that
                is more understandable to humans.
                Eventually, that code gets translated down to the computer's level into 0s and 1s.
            </p>

            <p>If we were to put this into a hierarchy, it might look like this:</p>

            <ol>
                <li>0s and 1s (machine code)</li>
                <li>Assembly</li>
                <li>Programming Languages (C, Java, Swift, ...)</li>
            </ol>
        </section>


        <section class="post-section">
            <h2>What is a Program?</h2>
            <p>A program is the set of instructions stored on disk or in memory.</p>
        </section>


        <section class="post-section">
            <h2>What Is a Process?</h2>
            <p>When you launch a program, the operating system creates a process. It's an instance of program.</p>
        </section>

        <section class="post-section">
            <h2>So?</h2>
            <p>
                Sometimes, analogies can make things harder to understand. I’m not going to give you an irrelevant one
                here.
                Imagine we wrote some code in the C programming language, and that code draws a blue rectangle on the
                screen.
                Our code is essentially a program a set of instructions.
            </p>

            <ul>
                <li>Get the window size</li>
                <li>Set the frame size to 25% of the window size.</li>
                <li>Draw rectangle</li>
                <li>Set the rectangle color to blue</li>
                <li>Rotate the rectangle</li>
                <li>Set the rotation speed</li>
                <li>And so on...</li>
            </ul>

            <p>
                As you can see, these are all instructions. Now, imagine we run this program. At this point, it’s no
                longer just
                a program, it becomes a process.
            </p>

            <p>
                We’ve actually created a process, which now has a process ID. It's using our computer’s resources such
                as the
                CPU, GPU, memory, and so on.
            </p>

            <p>Of course, the way these resources are used depends on the specific instructions.</p>
        </section>

        <section class="post-section">
            <h2>What is a Thread?</h2>
            <p>
                Finally, here we are. "Oh, I created a thread," or "This thread runs on a background thread" let's
                clarify what that means.
                A thread is an execution context within a process that can run independently. We can call them
                lightweight processes. Each thread has its own thread control block,
                which includes things like the thread ID, program counter, CPU registers, and its own stack. Threads
                within the same process share memory space and other resources.
            </p>

            <p>
                If we go back to our fictional C code.
                Now imagine we create two threads: one is doing the exact job described earlier, and the other is
                logging the
                system utilization of the computer.
            </p>

            <p>First thread → Drawing and displaying the rectangle</p>
            <p>Second thread → Logging the utilization of system resources</p>
        </section>

        <section class="post-section">
            <h3>Activity Monitor</h3>
            <p>
                This screenshot was taken from my MacBook. In the bottom-right corner, you can observe the thread and
                process counts.
                As expected, the number of threads is significantly higher than the number of processes.
            </p>

            <img class="post-img" src="/src/blog/post/computerScience/concurrency/activity_monitor_1.png"
                 alt="Activity Monitor Screenshot">
        </section>

        <section class="post-section">
            <h3>FirePlayer Process</h3>
            <p>
                In this screenshot, you can see the details of the FirePlayer process, including the number of threads in
                use, CPU time, parent process, and other relevant metrics.
            </p>

            <img class="post-img" src="/src/blog/post/computerScience/concurrency/activity_monitor_2.png"
                 alt="FirePlayer Process Details Screenshot">
        </section>

        <section class="post-section">
            <h3>FirePlayer Threads</h3>
            <p>
                Let’s explore further. When we click <b>Sample</b> from the process details in Activity Monitor, you can see
                the individual thread information.
            </p>

            <img class="post-img" src="/src/blog/post/computerScience/concurrency/thread_details_1.png"
            alt="FirePlayer Thread Details 1 Screenshot">

            <p>
                This application was written using SwiftUI with modern concurrency features like <code>async</code>, <code>await</code>,
                and <code>Task</code>.
                I did not use AppKit directly, yet you can observe that <code>App.main</code> eventually calls <code>[NSApplication
                run]</code> from AppKit.
                Also, I didn’t explicitly create most of these threads. So where did they originate? And how can we identify
                the threads we did create?
            </p>

            <img class="post-img" src="/src/blog/post/computerScience/concurrency/thread_details_2.png"
                 alt="FirePlayer Thread Details 2 Screenshot">

            <p>SwiftUI is a modern framework that runs on top of AppKit on macOS and UIKit on iOS.</p>

            <p>
                While SwiftUI abstracts away much of the underlying complexity, the macOS application lifecycle still goes
                through NSApplication, and many threads are created and managed internally by AppKit and the system.
            </p>

            <p>To identify a custom created thread in the sample, I assigned a name to it. Here's the relevant code:</p>

            <div class="code-container">
                <button class="copy-button" title="Copy">Copy</button>
                <pre><code class="lang-swift">let myQueue = DispatchQueue(label: "HEY_THIS_IS_THREAD")
myQueue.async {
    print("Hello from my thread, isMainThread:", Thread.isMainThread)
}
</code></pre>
            </div>

            <p>Now it is visible.</p>

            <img class="post-img" src="/src/blog/post/computerScience/concurrency/thread_details_3.png"
                 alt="FirePlayer Thread Details 3 Screenshot">

            <p>
                I think we’ve summarized threads, or at least gained a better understanding of how they exist within the OS.
                Of course, we could dive deeper into the details we saw in Activity Monitor and the thread samples, but
                let’s save that for another day.
            </p>
        </section>

        <section class="post-section">
            <h2>Concurrency</h2>
            <p>
                Concurrency is the ability to deal with multiple tasks at once, but not necessarily executing them
                simultaneously.
                If we go back in time, we had applications like Winamp music player and Internet Explorer running at the
                same time on
                an old single core Pentium II CPU. Yes, the CPU usage might have been around 40–50%, but it worked not just
                for those two processes, but the operating
                system was running many processes concurrently through rapid switching between them.
                So how can an OS run many processes at the same time with only one core? The processes aren't really working
                simultaneously - they're being managed concurrently.
            </p>

            <p>
                This is actually quite fascinating.
                Imagine you're waiting in a coffee queue, scrolling on your phone, and thinking about something in your
                head.
                Now I’m using an analogy haha. You’re multitasking with three things, but the key is: you’re not actively
                doing all three simultaneously.
            </p>

            <ul>
                <li>Waiting in the coffee queue → Process 1 → Waiting</li>
                <li>Scrolling → Process 2 → Active</li>
                <li>Thinking → Process 3 → Waiting</li>
            </ul>

            <p>
                Then, a second (or maybe three seconds) later, you stop scrolling and start thinking.
                Fifteen seconds later, the queue moves, and you stop thinking and scrolling to move forward.
                Just like us, the operating system does the same thing.
            </p>

            <p>
                That’s context switching.
                A context switch is when the system pauses a process or thread, saves its current state, and later restores
                it so it can continue running from where it left off.
            </p>
        </section>

        <section class="post-section">
            <h2>Parallelism</h2>
            <p>
                After hardware improvements, dual-core processors became available to consumers. Later on, smartphones even
                started featuring processors with 8 cores or more, bringing significant performance improvements to mobile
                devices.
                This meant that we could now run multiple tasks actively at the same time. However, doing so is not always
                easy and
                comes with some challenges.
            </p>

            <p>
                First, not everything can be parallelized. Some tasks depend on one another, meaning you cannot start the
                next task before the previous one is completed.
            </p>

            <p>
                Programs need to be written and designed specifically for parallel execution.
                Let’s go back to our earlier example.
            </p>

            <p>
                We can start logging the utilization of our system resources without waiting for the rectangle drawing logic
                to finish. The logging logic is not dependent on the drawing logic. Even if something goes wrong with the
                drawing logic, the logging logic can still continue to work. Sure, it might log 0% usage, but it
                doesn't rely on the drawing task to function.
            </p>

            <p>
                Thus, these two threads can run in parallel. If we have multicore hardware,
                one core can handle the CPU intensive task, while the other manages the I/O operation to the disk.
            </p>

            <p>
                Now, let me give you an example of a dependent task.
                Imagine we have a user in our database, and that user has some purchase history.
                We can't fetch the purchase history of the user and the user information in parallel.
                First, we have to retrieve the user; only then can we fetch their related purchase history.
                If the first task fails, the second one will fail too.
            </p>

            <p>
                Designing systems for parallelism can be challenging, and in some scenarios, implementing a parallel
                execution approach may not provide a huge performance boost. It's not linear your system will only be
                as fast as its slowest part. Parallelism also introduces complexity for engineers because
                it brings its own set of problems.
            </p>
        </section>

        <section class="post-section">
            <h2>Race Condition</h2>

            <p>
                Imagine we have multiple threads in our program, and those threads are running in parallel but maybe some of
                them need to access the same resource. Now, think beyond just drawing a rectangle: we’re also drawing
                triangles, squares, and many other shapes. Suppose we start 100 tasks, each responsible for drawing a different shape.
                Every drawing task first needs to access user data, which contains the drawing items count.
                After each drawing task is completed, it increments the user's drawing items count.
            </p>

            <p>
                Just imagine 100 tasks are started, and all of them will read and write to the same counter.
                How can the result be accurate?
            </p>

            <p>- First operation: drawing a rectangle. Reads current count: 2 → operation in progress</p>
            <p>- Second operation: drawing a triangle. Also reads current count: 2 → operation in progress</p>
            <p>...</p>
            <p>...</p>

            <p>
                Let's say the second operation finishes first and writes 3 (2+1).
                But then the first operation completes and also writes 3 (2+1) because it read the original value of 2
                before the second operation updated it. Since both operations read the same initial value and
                incremented it independently, we lost one increment.
            </p>

            <p>
                With 100 operations like this running concurrently, the final count will probably be incorrect, the count
                value will change depending on the timing of reads and writes.
            </p>

            <p>
                This situation is called a race condition - the final result depends on the unpredictable timing (or "race")
                between operations.
            </p>
        </section>

        <section class="post-section">
            <h2>Deadlock</h2>
            <p>
                Deadlock is another problem that can happen when multiple threads or processes are trying to access shared
                resources. Imagine two threads, and both need access to two different resources let’s call them Resource A
                and Resource B.
            </p>

            <p>- Thread 1 locks Resource A and waits for Resource B</p>
            <p>- Thread 2 locks Resource B and waits for Resource A</p>
            <p>Now both threads are stuck, each waiting for the other to release the resource. But that never happens.</p>
            <p>They can completely freeze your program, and the issue won’t fix itself unless handled properly.</p>
        </section>

        <section class="post-section">
            <h2>Starvation</h2>
            <p>
                Starvation is a different kind of problem. This happens when one thread or process waits for a resource,
                but it keeps getting ignored because other threads are always prioritized.
            </p>

            <p>
                Imagine a scenario where we have one thread that needs access to a shared resource,
                but higher priority threads keep getting access again and again. The lower priority thread waits...
                and waits... and waits.
            </p>

            <p>
                It never gets its turn not because it’s doing something wrong,
                but because the system never gives it a chance. That’s starvation.
            </p>

            <p>This can happen due to bad scheduling, priority systems, or poor resource management in the program.</p>
        </section>

        <section class="post-section">
            <h2>Conclusion</h2>
            <p>
                We’ve talked about the problems. Next, I will write a blog post about the solutions, and later on,
                we can explore the implementation details together maybe even in other programming languages.
            </p>
        </section>
    </main>
</article>
